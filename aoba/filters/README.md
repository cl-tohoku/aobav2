# parsers.py

## MecabParser

```py
from parsers import MecabParser

parser = MecabParser()
text = "å¾è¼©ã¯çŒ«ã§ã‚ã‚‹ã€‚åå‰ã¯ã¾ã ãªã„ã€‚"
parsed_text = parser(text)
```

# normalizers.py

## SentenceNormalizer

```py
from normalizers import SentenceNormalizer

normalizer = SentenceNormalizer()
text = "ï¾”ï½¯ï¾ï½°...ï¼ˆç¬‘ï¼‰ç¬‘wwwğŸ˜„..."
normalized_text = normalizer(text)
```

# bert_predictors

## NextUtterancePredictor

```py
from bert_predictors import NextUtterancePredictor

model = "/work01/slud_livechat_2020/mlm-checkpoint-43000-pytorch-model.bin"
contexts = ["ä»Šæ—¥ã¯ã„ã„å¤©æ°—ã§ã™ã­", "å¤–ã«éŠã³ã«ã„ãã¾ã—ã‚‡ã†"]
response_candidates = ["ã„ã„ã§ã™ã­", "ã©ã“ã„ãã¾ã™ã‹ï¼Ÿ"]

predictor = NextUtterancePredictor(model)
results = predictor(contexts, response_candidates)
```

## JsnliPredictor

```py
from jsnli import JsnliPredictor

parser = argparse.ArgumentParser(description='')
parser = JsnliPredictor.add_parser(parser)
args = parser.parse_args()

predictor = JsnliPredictor(args.model_jsnli)

premise = "ãƒ¯ã‚¯ãƒãƒ³æ‰“ã£ãŸã‚‰å‰¯ä½œç”¨ãŒè¾›ã‹ã£ãŸã€‚"
hypothesis = "å…·ä½“çš„ã«ã©ã‚“ãªå‰¯ä½œç”¨ãŒã‚ã‚Šã¾ã—ãŸï¼Ÿ"
result = predictor(premise, hypothesis)

# [[{'label': 'entailment', 'score': 0.00027919572312384844}, {'label': 'neutral', 'score': 0.0010284266900271177}, {'label': 'contradiction', 'score': 0.9986923933029175}]]
```